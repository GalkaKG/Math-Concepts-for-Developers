{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "\n",
    "# Write your imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Combinatorics Exercise\n",
    "## Probabilistic Events. Combinatorics and Counting. Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. Exploring Distribution Parameters\n",
    "A good idea to visualize and explore the parameters of various distributions is just to plot them.\n",
    "\n",
    "We can do this in either one of two ways:\n",
    "1. Draw (generate) many random variables which follow that distribution. Plot their histogram\n",
    "2. Write the distribution function directly and plot it\n",
    "\n",
    "Either of these will work but the second approach will give us better looking results. [`scipy.stats`](https://docs.scipy.org/doc/scipy-0.19.1/reference/stats.html) has a lot of built-in distributions that we can use. Each of them has its own use cases.\n",
    "\n",
    "It's very important that we plot discrete and continuous distributions in different ways. **We must not make discrete distributions look continuous**. That is, discrete distributions are only defined for integer number of trials: $n \\in \\mathbb{N}$.\n",
    "\n",
    "Let's plot the binomial and Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binomial_distribution(x, n, p):\n",
    "    \"\"\"\n",
    "    Plots the binomial distribution with parameters n and p. The parameter x specifies the values\n",
    "    where the function is evaluated at\n",
    "    \"\"\"\n",
    "    binomial = scipy.stats.binom.pmf(x, n, p)\n",
    "    plt.scatter(x, binomial, color = \"blue\")\n",
    "    plt.vlines(x, 0, binomial, color = \"blue\", linewidth = 5, alpha = 0.5)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_gaussian_distribution(mu, sigma, x):\n",
    "    \"\"\"\n",
    "    Plots the Gaussian distribution with parameters mu and sigma. The parameter x specifies \n",
    "    the values where the function is evaluated at\n",
    "    \"\"\"\n",
    "    gaussian = scipy.stats.norm.pdf(x, loc = mu, scale = sigma)\n",
    "    plt.plot(x, gaussian, color = \"blue\")\n",
    "    plt.show()\n",
    "    \n",
    "x_binomial = np.arange(1, 10)\n",
    "plot_binomial_distribution(x_binomial, 10, 0.5)\n",
    "\n",
    "x_gaussian = np.linspace(-3, 3, 1000)\n",
    "plot_gaussian_distribution(0, 1, x_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look similar. That's with a good reason: the Gaussian distribution is a generalization of the binomial distribution as $n \\rightarrow \\infty$.\n",
    "\n",
    "What do these parameters specify exactly? Let's find out. \n",
    "\n",
    "Take the binomial distribution. Keep $p = 0.5$ and change $n$. Plot several values of $n$ in the same plot, with different colors. **What values to choose?** Remember that $n$ was the number of experiments, so it should be an integer $\\ge 1$.\n",
    "\n",
    "Now keep $n$ at some reasonable value (a number between 10 and 30 should be good) and change $p$. $p$ is a probability so its values must be between 0 and 1.\n",
    "\n",
    "What can you conclude? How does the function shape change? When is it symmetrical and when it is not?\n",
    "\n",
    "Perform the same kind of operations on $\\mu$ and $\\sigma$ with the Gaussian distribution. What do these parameters represent?\n",
    "\n",
    "If you get stuck, try to find what the distribution functions should look like on the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Central Limit Theorem\n",
    "The [**Central Limit Theorem**](https://en.wikipedia.org/wiki/Central_limit_theorem) tells us that no matter what quirky functions we have, their sum is going to be distributed according to the normal distribution. Let's prove this.\n",
    "\n",
    "Consider the following functions:\n",
    "$$ f(x) = 1 $$\n",
    "\n",
    "$$ f(x) = 2x $$\n",
    "\n",
    "$$ f(x) = 3x^2 $$\n",
    "\n",
    "$$ f(x) = 4\\lvert x - 0,5\\rvert $$\n",
    "\n",
    "$$ f(x) = 2 - 4\\lvert x - 0,5\\rvert $$\n",
    "\n",
    "For each of these functions `f`:\n",
    "1. Generate a big array of, say, 2000 values `x` between 0 and 1\n",
    "2. Generate the array $f(x)$ and plot $f(x)$. This is just to see how the original function looks\n",
    "3. Create 1000 experiments like this:\n",
    "    1. Generate 25 random values $x$ between 0 and 1: `np.random.rand(25)`\n",
    "    3. Generate $y = f(x)$\n",
    "    2. Sum all 25 values $y$\n",
    "    3. Add the sum to the array of sums\n",
    "4. Plot the distribution of 1000 sums\n",
    "\n",
    "If you want, you can experiment with the \"settings\" even more - try changing the number of experiments, number of sums, range of $x$, functions, etc.\n",
    "\n",
    "What do you get? Can you experiment with a combination of functions? When is the normal distribution a good approximation of the real distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. Birthday Paradox\n",
    "How many people do we need to have in a room, so that the probability of two people sharing a birthday is $p(A) > 0,5$?\n",
    "\n",
    "We suppose no leap years, so a year has 365 days. We could expect that we need about $365/2=182$ people. Well, the truth is a bit different.\n",
    "\n",
    "#### Solution\n",
    "**Random variable:** $A$: probability that two people share a birthday.\n",
    "\n",
    "It's sometimes easier to work with the complementary variable: $\\bar{A}$ - probability that **no people** share a birthday. \n",
    "\n",
    "Let's suppose we have $r$ people in the room. Of course, if $r = 1$, e.g. only one person, the probability is $1$ (there's no one to share a birthday with). If $r >= 365$, the probability must be 1 (by the so-called [pigeonhole principle](https://en.wikipedia.org/wiki/Pigeonhole_principle): if we have 366 people and 365 days, there's at least one day with a pair of people).\n",
    "\n",
    "Order the people 1 to $r$. Every person's birthday is independent, so that means 365 days for the first, 365 days for the second, and so on: $365^r$ birthday possibilities in total.\n",
    "\n",
    "We want no duplications of birthdays. The first person has 365 days to choose from, the second has 364, and so on. The $r$th person has $365-r+1$ days to choose from. Total: $365.364.363.\\cdots.(365 - r + 1)$\n",
    "\n",
    "The probability that no people share the same birthday is the fraction of all non-shared birthdays to all possible birthdays:\n",
    "$$ p(\\bar{A})=\\frac{365.364.363.\\cdots.(365 - r + 1)}{365^r} $$\n",
    "\n",
    "We're interested in $A$, not $\\bar{A}$ and we know that these are complementary, so their probabilities add up to 1\n",
    "$$p(A) = 1 - p(\\bar{A})$$\n",
    "\n",
    "Write a function which plots the probability of $r$ people sharing a birthday. Remember this is a discrete distribution and should be plotted like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_birthday_probability(r):\n",
    "    \"\"\"\n",
    "    Returns the probability of r people sharing the same birthday. A year is\n",
    "    supposed to have 365 days\n",
    "    \"\"\"\n",
    "    # Write your code here\n",
    "    pass\n",
    "\n",
    "probabilities = [calculate_birthday_probability(r) for r in np.arange(2, 366)]\n",
    "# TODO: Plot the probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At how many people do you see a transition from $p(A) < 0,5$ to $p(A) > 0,5$?\n",
    "\n",
    "**Spoiler alert:** It's 23 people.\n",
    "\n",
    "Why so few? We're comparing everyone's birthday against everyone else's. We should **NOT** count the number of people, but the number of comparisons. In a room of 23 people, there are 252 total comparisons.\n",
    "\n",
    "In general, we could get a 50% chance of match using $\\sqrt{n}$ people in $n$ days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Breaking Cryptography: Birthday Attack\n",
    "We already saw that if we have $n$ days in one year, it takes about $\\sqrt{n}$ people to have a 50% chance of two people sharing a birthday. This is used in cryptography for the so-called **birthday attack**.\n",
    "\n",
    "Let's first introduce **hashing functions**. A hashing function is a function which takes text (bits) of any length and  **returns a fixed number of bits**. There are many such functions. Some of them are completely insecure and **ARE NOT** used in cryptography. They're useful for other purposes, such as hash tables.\n",
    "\n",
    "Important properties of hashing functions:\n",
    "1. The output will have a fixed length, no matter whether the input is an empty string, one character, a full sentence, a full book or the entire history of mankind\n",
    "2. A concrete input will always produce the same output\n",
    "\n",
    "One such hashing function is **MD5**. It produces 128-bit hashes (32 hexadecimal symbols). This means that it takes the space of all possible texts and converts it to $2^{128} \\approx 3.10^{38}$ possible hashes. Since the inputs are much more, by the pigeonhole principle, we can expect that many inputs will produce the same output. This is called a **hashing collision**.\n",
    "\n",
    "The birthday paradox tells us that using $\\sqrt{n} = 2^{64} \\approx 2.10^{19}$ hashes, we have a 50% probability of collision. This is still a very large number but compare it to $3.10^{38}$ - the difference is immense.\n",
    "\n",
    "You can see what these numbers mean in terms of CPU speed [here](https://blog.codinghorror.com/speed-hashing/).\n",
    "\n",
    "There are other algorithms which are even faster. The fastest one returns about $2^{18}$ hashes before it finds a collision.\n",
    "\n",
    "Another clever attack is using **rainbow tables**. These are massive dictionaries of precomputed hashes. So, for example, if the input is `password123`, its MD5 hash is `482c811da5d5b4bc6d497ffa98491e38`. Every time an algorithm sees this hash, it can convert it to its input. \n",
    "\n",
    "Rainbow tables work because humans are more predictable than algorithms. When implementing any cryptography, remember that **humans are always the weakest factor of any cryptographic system**.\n",
    "\n",
    "**Optional:** Write a function that finds collisions in **MD5** or **SHA1**. See [this](https://www.mscs.dal.ca/~selinger/md5collision/) demo for a good example, or [this StackOverflow post](https://crypto.stackexchange.com/questions/1434/are-there-two-known-strings-which-have-the-same-md5-hash-value) for more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. Having Fun with Functions. Fourier Transform\n",
    "Sometimes we can plot a **parametric curve**. We choose a parameter $t$, in this case $t \\in [0; 2\\pi]$. We then plot $x$ and $y$ as functions of $t$.\n",
    "\n",
    "Plot the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 2 * np.pi, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = -(721 * np.sin(t)) / 4 + 196 / 3 * np.sin(2 * t) - 86 / 3 * np.sin(3 * t) - 131 / 2 * np.sin(4 * t) + 477 / 14 * np.sin(5 * t) + 27 * np.sin(6 * t) - 29 / 2 * np.sin(7 * t) + 68 / 5 * np.sin(8 * t) + 1 / 10 * np.sin(9 * t) + 23 / 4 * np.sin(10 * t) - 19 / 2 * np.sin(12 * t) - 85 / 21 * np.sin(13 * t) + 2 / 3 * np.sin(14 * t) + 27 / 5 * np.sin(15 * t) + 7 / 4 * np.sin(16 * t) + 17 / 9 * np.sin(17 * t) - 4 * np.sin(18 * t) - 1 / 2 * np.sin(19 * t) + 1 / 6 * np.sin(20 * t) + 6 / 7 * np.sin(21 * t) - 1 / 8 * np.sin(22 * t) + 1 / 3 * np.sin(23 * t) + 3 / 2 * np.sin(24 * t) + 13 / 5 * np.sin(25 * t) + np.sin(26 * t) - 2 * np.sin(27 * t) + 3 / 5 * np.sin(28 * t) - 1 / 5 * np.sin(29 * t) + 1 / 5 * np.sin(30 * t) + (2337 * np.cos(t)) / 8 - 43 / 5 * np.cos(2 * t) + 322 / 5 * np.cos(3 * t) - 117 / 5 * np.cos(4 * t) - 26 / 5 * np.cos(5 * t) - 23 / 3 * np.cos(6 * t) + 143 / 4 * np.cos(7 * t) - 11 / 4 * np.cos(8 * t) - 31 / 3 * np.cos(9 * t) - 13 / 4 * np.cos(10 * t) - 9 / 2 * np.cos(11 * t) + 41 / 20 * np.cos(12 * t) + 8 * np.cos(13 * t) + 2 / 3 * np.cos(14 * t) + 6 * np.cos(15 * t) + 17 / 4 * np.cos(16 * t) - 3 / 2 * np.cos(17 * t) - 29 / 10 * np.cos(18 * t) + 11 / 6 * np.cos(19 * t) + 12 / 5 * np.cos(20 * t) + 3 / 2 * np.cos(21 * t) + 11 / 12 * np.cos(22 * t) - 4 / 5 * np.cos(23 * t) + np.cos(24 * t) + 17 / 8 * np.cos(25 * t) - 7 / 2 * np.cos(26 * t) - 5 / 6 * np.cos(27 * t) - 11 / 10 * np.cos(28 * t) + 1 / 2 * np.cos(29 * t) - 1 / 5 * np.cos(30 * t)\n",
    "y = -(637 * np.sin(t)) / 2 - 188 / 5 * np.sin(2 * t) - 11 / 7 * np.sin(3 * t) - 12 / 5 * np.sin(4 * t) + 11 / 3 * np.sin(5 * t) - 37 / 4 * np.sin(6 * t) + 8 / 3 * np.sin(7 * t) + 65 / 6 * np.sin(8 * t) - 32 / 5 * np.sin(9 * t) - 41 / 4 * np.sin(10 * t) - 38 / 3 * np.sin(11 * t) - 47 / 8 * np.sin(12 * t) + 5 / 4 * np.sin(13 * t) - 41 / 7 * np.sin(14 * t) - 7 / 3 * np.sin(15 * t) - 13 / 7 * np.sin(16 * t) + 17 / 4 * np.sin(17 * t) - 9 / 4 * np.sin(18 * t) + 8 / 9 * np.sin(19 * t) + 3 / 5 * np.sin(20 * t) - 2 / 5 * np.sin(21 * t) + 4 / 3 * np.sin(22 * t) + 1 / 3 * np.sin(23 * t) + 3 / 5 * np.sin(24 * t) - 3 / 5 * np.sin(25 * t) + 6 / 5 * np.sin(26 * t) - 1 / 5 * np.sin(27 * t) + 10 / 9 * np.sin(28 * t) + 1 / 3 * np.sin(29 * t) - 3 / 4 * \\\n",
    "    np.sin(30 * t) - (125 * np.cos(t)) / 2 - 521 / 9 * np.cos(2 * t) - 359 / 3 * np.cos(3 * t) + 47 / 3 * np.cos(4 * t) - 33 / 2 * np.cos(5 * t) - 5 / 4 * np.cos(6 * t) + 31 / 8 * np.cos(7 * t) + 9 / 10 * np.cos(8 * t) - 119 / 4 * np.cos(9 * t) - 17 / 2 * np.cos(10 * t) + 22 / 3 * np.cos(11 * t) + 15 / 4 * np.cos(12 * t) - 5 / 2 * np.cos(13 * t) + 19 / 6 * np.cos(14 * t) + \\\n",
    "    7 / 4 * np.cos(15 * t) + 31 / 4 * np.cos(16 * t) - np.cos(17 * t) + 11 / 10 * np.cos(18 * t) - 2 / 3 * np.cos(19 * t) + 13 / 3 * np.cos(20 * t) - 5 / 4 * np.cos(21 * t) + 2 / 3 * np.cos(\n",
    "        22 * t) + 1 / 4 * np.cos(23 * t) + 5 / 6 * np.cos(24 * t) + 3 / 4 * np.cos(26 * t) - 1 / 2 * np.cos(27 * t) - 1 / 10 * np.cos(28 * t) - 1 / 3 * np.cos(29 * t) - 1 / 19 * np.cos(30 * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting... \n",
    "\n",
    "Have a closer look at the variables `x` and `y`. Note that they're linear combinations of sines and cosines. There's nothing more except sines and cosines, multiplied by coefficients. How are these able to generate the picture? Can we generate any picture?\n",
    "\n",
    "Yes, we can generate pretty much anything and plot it as a parametric curve. See [this](https://www.wolframalpha.com/input/?i=Schroedinger+cat+bra-ket+curve) for example.\n",
    "\n",
    "It turns out that **every function**, no matter what, can be represented as a linear combination of sines and cosines. This is the basis of the **Fourier transform**. We'll look at it from two different perspectives: the algebraic one and the practical one.\n",
    "\n",
    "#### Algebraic perspective: Why does this transform exist? What does it mean?\n",
    "All functions form a **vector space**. We can see them as vectors. These vectors have infinitely many components which correspond to the infinitely many values $x \\in (-\\infty; \\infty)$. The function space has infinitely many dimensions.\n",
    "\n",
    "We can find a basis in that space. After we've found a basis, we can express any other function as a linear combination of the basis functions. Any set of infinitely many linearly independent functions will work. But that doesn't help at all...\n",
    "\n",
    "We know that the best kind of basis is an *orthonormal basis*. This means that all basis vectors are orthogonal and each basis vector has \"length\" 1. \n",
    "\n",
    "Two vectors are orthogonal if their dot product is zero. Similarly, two functions are defined to be orthogonal if their  product is zero, like this:\n",
    "$$ \\int_a^b f(x)g(x)\\,\\text{d}x = 0 $$\n",
    "\n",
    "It can be shown that $1$, $\\cos(mx)$ and $\\sin(nx)$ ($m,n \\in \\mathbb{N}$) are orthogonal. So, the basis formed by them is orthogonal. They can also be made orthonormal if we divide by their norm. The norm of a function is defined by **functional analysis** - an area of mathematics which treats functions as vectors. We won't go into much more detail now. The norm for $1$ is 1, the norm for the trigonometric functions is $1/\\sqrt{2}$.\n",
    "\n",
    "The takeaway is that ${1, \\sqrt{2}\\cos(mx), \\sqrt{2}\\sin(nx),\\ m,n \\in \\mathbb{N}}$ is an orthonormal basis in the function space. \n",
    "\n",
    "All periodic functions with period $P$ can be described as linear combinations of these:\n",
    "$$ f(x) = \\frac{a_0}{2} + \\sum\\left(a_n\\cos\\left(\\frac{2\\pi nx}{P}\\right)+b_n\\sin\\left(\\frac{2\\pi nx}{P}\\right)\\right) $$\n",
    "\n",
    "This definition extends to non-periodic functions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering perspective\n",
    "In engineering, the Fourier transform **converts a function of time to a function of frequency**. The function of time is called a **signal**, and the function of frequency is the **spectrum** of that signal. There is a pair of functions - one inverts the other. We have two different options:\n",
    "1. We can inspect the spectrum\n",
    "2. We can modify the spectrum\n",
    "\n",
    "This means that if some operation is very easy to perform in the spectrum we can perform it there using these steps:\n",
    "1. Create the spectrum from the signal - Fourier transform\n",
    "2. Perform the operation, e.g. remove a specific frequency\n",
    "3. Create the corrected signal from the corrected spectrum - inverse Fourier transform\n",
    "\n",
    "One example usage is in audio processing. An audio signal is a  1D array of **samples** (numbers). Each audio signal has a *bitrate* which tells us how many samples are there in one second. Since audio is a function of time, we can easily get its spectrum.\n",
    "\n",
    "Some algorithms on images use the spectrum as well. The idea is exactly the same.\n",
    "\n",
    "Compare this entire process to how we created a **histogram**. Plotting a random variable $X$ as a function of the trial number is essentially plotting a function of time. To get the histogram, we counted how many times we saw each particular value. This is the same as taking the spectrum of the random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5. Working with Audio Files. Using the Fourier Transform\n",
    "In Python, it's easiest to work with `.wav` files. If we have other files, we can convert them first. To load audio files, we can use `scipy.io.wavfile`. Load the `c-note.wav` file. Use only one channel, e.g. the left one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitrate, audio = scipy.io.wavfile.read(\"c-note.wav\")\n",
    "left_channel = audio[:, 0]\n",
    "right_channel = audio[:, 1]\n",
    "plt.plot(left_channel)\n",
    "plt.xlabel(\"Sample number\") # To get seconds, divide by the bitrate\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_fft = fft(left_channel)\n",
    "\n",
    "# fftfreq() returns the frequences in number of cycles per sample. Since we have `bitrate` samples in one second,\n",
    "# to get the frequencies in Hz, we have to multiply by the bitrate\n",
    "frequencies = fftfreq(len(left_channel)) * bitrate\n",
    "\n",
    "plt.plot(frequencies, left_fft)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the signal is symmetric. This is always the case with Fourier transform. We are interested in only half the values (the ones which are $\\ge 0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frequencies, left_fft)\n",
    "plt.xlim((0, 15000))\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some frequencies have higher intensities than others. Also, they are evenly spaced. This is because the sample is only one note: C4, which has a fundamental frequency of $261,6Hz$. Most other \"loud\" frequencies are a multiple of the fundamental frequency: these are called **obertones**. There are other frequencies as well. The combination of frequencies which one instrument emphasizes and the ones that it dampens (i.e. makes quiet) determines the specific sound, or **timbre** of that instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frequencies, left_fft)\n",
    "plt.xlim((240, 290))\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting application of this is removal of unwanted frequencies. Look at [this video](https://www.youtube.com/watch?v=ATVbnilxIrs) for example. The highly annoying vuvuzela of 2010 World Cup turns out to produce only a single frequency which can be very easily removed from a recording.\n",
    "\n",
    "Another interesting application of Fourier transform is filters (in audio and images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Problem 6. Breaking MD5 in Different Ways\n",
    "One relatively fast algorithm: $2^{18}$ instead of $2^{19}$ hashes for a 50% probability is described in [this](https://eprint.iacr.org/2013/170.pdf) article. It's the fastest known to date to break the MD5 function by brute force. Get familiar with it and implement the algorithm. Try to show how it works on some common (and short) plaintexts.\n",
    "\n",
    "Experiment with other types of breaking the hash, for example using rainbow tables.\n",
    "\n",
    "You can use the following checklist:\n",
    "* What is a hash function? When are hash functions used?\n",
    "* What is a cryptographic hash function?\n",
    "* Why and how is a collision possible?\n",
    "* What is a collision attack?\n",
    "* What are the most common ways to attack hash functions?\n",
    "    * Which cryptographic hash functions are no longer considered secure? Why?\n",
    "* Why do websites have to store hashes of passwords instead of plaintext?\n",
    "    * How does user login work?\n",
    "* What is the \"birthday attack\"?\n",
    "    * Provide an example of two plaintexts which produce the same hash\n",
    "* What is the algorithm in the article about?\n",
    "    * Implement it and show the result\n",
    "* What is a rainbow table?\n",
    "    * Try breaking common passwords using a rainbow table. You can generate one or use some table from the internet (e.g. English words and letters, their modifications, leaked passwords, etc.)\n",
    "    * Even better, try a rainbow table first. If it doesn't work, try brute force\n",
    "* How can a website protect its database against rainbow tables?\n",
    "    * What is a \"salt\"? Additionally, what is \"pepper\"?\n",
    "    * Is it always secure to hash a password multiple times? What advantages and disadvantages does this provide?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Problem 7. Audio Filters and Equalizers\n",
    "Examine the behaviour of different filters and their influence on the input signal. The main kinds of filters are\n",
    "* High-pass / low-pass\n",
    "* Band-pass / band-stop\n",
    "\n",
    "You can use the following checklist:\n",
    "* What is a signal? What is time domain? What is frequency domain?\n",
    "* How does the Fourier transform work?\n",
    "    * Provide one (or more) examples with code\n",
    "    * Optionally, show plots of some common functions (sine, step, pulse, sinc, gaussian) and their Fourier spectrums\n",
    "* What is a filter?\n",
    "* How does each type of filter work?\n",
    "    * Provide examples, possibly with real data\n",
    "* How do we combine filters and why?\n",
    "* What is an equalizer?\n",
    "    * Optionally, create an equalizer program or plugin that allows the user to emphasize or dampen different frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Problem 8. Error-Correcting Codes\n",
    "In communication and data storage, it's important to prevent, detect, and possibly correct errors (such as errors in data transmission). There are various schemes to implement such correction, mainly by sending additional info with the data. A popular such scheme is the [Hamming code](https://en.wikipedia.org/wiki/Hamming_code). Your task is to explore how it works, implement an example, and compare it to other error detection and correction mechanisms.\n",
    "* What is an error-correcting code? Why are they important?\n",
    "* What are the different types of error-correcting codes? Provide real-world examples.\n",
    "* What is a **Hamming code**? Describe the history and / or derive the formula(s). \n",
    "* What are parity bits and how do we use them?\n",
    "* What is the Hamming distance and what is its significance? How is it related to other distance metrics for text / bit sequences?\n",
    "* Deeper dive into mathematics:\n",
    "    * Derive the general formula for the number of parity bits required for a given number of data bits.\n",
    "    * Explain the process of encoding data using Hamming codes. How are parity bits positioned in the data?\n",
    "    * Describe the process of detecting and correcting errors using Hamming codes. How are syndrome vectors used in this process?\n",
    "* Implement encoding / decoding, error detection and error correction\n",
    "    * Simplest case - illustrate one-bit detection / correction\n",
    "    * Apply the encoding scheme to a real-world scenario\n",
    "    * Compare your implementation to a Python library. Discuss efficiency, timing, code quality, etc.\n",
    "* Discussion:\n",
    "    * What are the limitations of Hamming codes? How do more advanced error-correcting codes address these limitations?\n",
    "    * Research at least one other error-correcting codes used in industry. Compare their complexity and effectiveness with Hamming codes. Provide at least one real-world example (and edge cases, if possible)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Problem 9. Probabilistic Data Structures\n",
    "A very interesting application of probability in computer science is a kind of data structures which have a probabilistic behaviour. Examples of these are **Bloom filter**, **Skip list**, **Count-min sketch** and **HyperLogLog**.\n",
    "\n",
    "Research how one of these structures works. Or write about many of them, if you wish. You can use the following checklist as a guide:\n",
    "* What is a data structure? \n",
    "* What is a probabilistic data structure?\n",
    "    * Where does the probabilistic behaviour emerge?\n",
    "    * What advantages do these structures provide?\n",
    "* For your chosen structure, how is it constructed?\n",
    "    * What parts do you need? What are the details?\n",
    "* How does the structure work?\n",
    "    * What operations can you do?\n",
    "    * What are the typical probabilities associated with these operations?\n",
    "* Analyze the structure\n",
    "    * Analyze the runtimes for all operations\n",
    "    * Analyze the space usage\n",
    "    * Compare to a similar, non-probabilistic data structure\n",
    "    * What advantages does the new data structure have? What drawbacks do you need to be aware of?\n",
    "* Give at least one example where this structure is useful\n",
    "    * E.g., Bloom filter - spell checkers\n",
    "    * Analyze the use case\n",
    "    * If possible, implement the use case\n",
    "    * Display some metrics (e.g. % conserved space, % reduced time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
